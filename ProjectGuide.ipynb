{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Basic information About The Project: </h1>\n",
    "<p> This is a template file for Optimizaion Algorithms Based on Evolutionary Computing. Please read all the instruction before starting the project. </p>\n",
    "<p> You can finish entire project in this file, or you can use this file as guide and submit separated scripts</p>\n",
    "<h3> You can achieve maximum points (80) only on first exam period </h3>\n",
    "<p> Second Exam period is -5 points (1.25 points per LO) (max 75) </p>\n",
    "<p>  Third Exam period is -10 points (1.25 points per LO)(max 70) </p>\n",
    "<p>  Fourth Exam period is -15 points (1.25 points per LO) (max 65) </p>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<h3> Project Points distribution (80 points in total) </h3>\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Task</th>\n",
    "            <th>Points LO1</th>\n",
    "            <th>Points LO2</th>\n",
    "            <th>Points LO3</th>\n",
    "            <th>Points LO4</th>\n",
    "            <th>Total Points</th>\n",
    "            <th>Question Title</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Task 1</td>\n",
    "            <td>0.5</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>0</td>\n",
    "            <td>2.5</td>\n",
    "            <td>Task 1. Implement Hill-Climber Algorithm</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Task 2</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>4</td>\n",
    "            <td>Task 2. Evaluate time complexity</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Task 3</td>\n",
    "            <td>0.5</td>\n",
    "            <td>3</td>\n",
    "            <td>3</td>\n",
    "            <td>0</td>\n",
    "            <td>6.5</td>\n",
    "            <td>Task 3. Implement Simulated Annealing</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Task 4</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>4</td>\n",
    "            <td>Task 4. Evaluate implemented temperature schedulers</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Task 5</td>\n",
    "            <td>1</td>\n",
    "            <td>3</td>\n",
    "            <td>3</td>\n",
    "            <td>0</td>\n",
    "            <td>7</td>\n",
    "            <td>Task 5. Implement Particle Swarm Optimization algorithm</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Task 6</td>\n",
    "            <td>0.5</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>0.5</td>\n",
    "            <td>3</td>\n",
    "            <td>Task 6. Experiment with C1 and C2 hyperparameters</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Task 7</td>\n",
    "            <td>0.5</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>0.5</td>\n",
    "            <td>3</td>\n",
    "            <td>Task 7. Experiment with C1=0 and C2=1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Task 8</td>\n",
    "            <td>1</td>\n",
    "            <td>3</td>\n",
    "            <td>3</td>\n",
    "            <td>1</td>\n",
    "            <td>8</td>\n",
    "            <td>Task 8. Implement Ant Colony Optimization</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Task 9</td>\n",
    "            <td>1</td>\n",
    "            <td>2</td>\n",
    "            <td>2</td>\n",
    "            <td>1</td>\n",
    "            <td>6</td>\n",
    "            <td>Task 9. Experiment with Ant Colony Optimization</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Task 10</td>\n",
    "            <td>0</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>3</td>\n",
    "            <td>Task 10. Implement Genetic Algorithm (GA) Optimization</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Task 11</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>4</td>\n",
    "            <td>Task 11. Experiment with Genetic Algorithm (GA) Optimization Hyperparameters</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Task 12</td>\n",
    "            <td>0</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>0</td>\n",
    "            <td>2</td>\n",
    "            <td>Task 12. Use pyGAD library</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Task 13</td>\n",
    "            <td>0</td>\n",
    "            <td>2</td>\n",
    "            <td>2</td>\n",
    "            <td>0</td>\n",
    "            <td>4</td>\n",
    "            <td>Task 13. The Needleman-Wunsch Algorithm</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Task 14</td>\n",
    "            <td>1</td>\n",
    "            <td>0</td>\n",
    "            <td>0</td>\n",
    "            <td>1</td>\n",
    "            <td>2</td>\n",
    "            <td>Task 14. Time complexity of The Needleman-Wunsch Algorithm</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Task 15</td>\n",
    "            <td>0</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>3</td>\n",
    "            <td>Task 15. Implement basic Gradient Descent</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Task 16</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>1</td>\n",
    "            <td>4</td>\n",
    "            <td>Task 16. Experiment basic Gradient Descent</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Task 17</td>\n",
    "            <td>1</td>\n",
    "            <td>2</td>\n",
    "            <td>2</td>\n",
    "            <td>1</td>\n",
    "            <td>6</td>\n",
    "            <td>Task 17. The end game - part 1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Task 18</td>\n",
    "            <td>1</td>\n",
    "            <td>3</td>\n",
    "            <td>3</td>\n",
    "            <td>1</td>\n",
    "            <td>8</td>\n",
    "            <td>Task 18. The end game - part 2</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><strong>Total Project Points</strong></td>\n",
    "            <td><strong>12</strong></td>\n",
    "            <td><strong>28</strong></td>\n",
    "            <td><strong>28</strong></td>\n",
    "            <td><strong>12</strong></td>\n",
    "            <td><strong>80</strong></td>\n",
    "            <td></td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<h3> Project Defense Tips: </h3>\n",
    "\n",
    "*   You do not have to use this file. You can have each task in separated file or 2 tasks in the same file, grouped by the topic. Up to you...\n",
    "*   You have to understand your code\n",
    "*   You have to be able to point to specific functionality of your code. For example, how do you compute acceptance probability? Point to function and explain\n",
    "*   You can answer on question by showing the plots you made. Make sure they are informative, because they will help you on project defense\n",
    "*   You have to use appropriate terminology, based on lectures and exercises.\n",
    "*   All algorithm implementations should work in multi-dimensional space even if example objective function is one-dimensional. The idea is that your implementation can work with any objective function.\n",
    "\n",
    "\n",
    "<h3> How will your project be graded? </h3>\n",
    "\n",
    "*   The solution that does not run will result with 0 points\n",
    "*   Within each task, read all the questions as they contribute to LO points\n",
    "*   If you do not understand your implementation, we will assume chatGPT (or other copy-pasting) which will result with disciplinary committee hearing\n"
   ],
   "metadata": {
    "id": "Tc0B9sJSRemh"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Task 1. Implement Hill-Climber Algorithm </h2> which is capable of solving N-dimensional problem. In the code block you can find example objective functions. Feel free to use any multi-dimensional objective function. The idea is that your implementation works the same for 1-dim and N-dim objective functions."
   ],
   "metadata": {
    "id": "t8V-UzOFTXw9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kej6DAx7Rbpn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def objective1(x): # in this example X is 2D\n",
    "    a = 1\n",
    "    b = 100\n",
    "    return (a - x[0])**2 + b * (x[1] - x[0]**2)**2\n",
    "\n",
    "def objective2(x):\n",
    "    sum_part = sum(x_i**2 for x_i in x) / 4000\n",
    "    product_part = np.prod(np.cos(x / np.sqrt(np.arange(1, len(x) + 1))))\n",
    "    return 1 + sum_part - product_part\n",
    "x = np.array([0.2, 1.0, 23.3, 1.2, 2.5])\n",
    "value = objective2(x)\n",
    "print(f'objective2 function value at {x}: {value}')\n",
    "x = np.array([1.2, 23.2])\n",
    "value = objective1(x)\n",
    "print(f'objective1 function value at {x}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "UrKyPhv6a8XA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Task 2. Evaluate time complexity</h2> of your Hill-Climber implementation. This include varying the input size from, for example, 1 to 10000 ( you might need more) and record the running time each time. You can use this implementation for all time complexity evaluations later in the project. This should result in a similar table: <br>\n",
    "<h2 style=\"text-align: center;\">Time Complexity Evaluation Table</h2>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>input_size_max_iter</th>\n",
    "        <th>input_size_local_search</th>\n",
    "        <th>time_max_iter (s)</th>\n",
    "        <th>time_local_search (s)</th>\n",
    "        <th>total_time (s)</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>100</td>\n",
    "        <td>50</td>\n",
    "        <td>0.12</td>\n",
    "        <td>0.05</td>\n",
    "        <td>0.17</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>200</td>\n",
    "        <td>100</td>\n",
    "        <td>0.25</td>\n",
    "        <td>0.09</td>\n",
    "        <td>0.34</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>300</td>\n",
    "        <td>150</td>\n",
    "        <td>0.38</td>\n",
    "        <td>0.12</td>\n",
    "        <td>0.50</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>400</td>\n",
    "        <td>200</td>\n",
    "        <td>0.51</td>\n",
    "        <td>0.15</td>\n",
    "        <td>0.66</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>500</td>\n",
    "        <td>250</td>\n",
    "        <td>0.70</td>\n",
    "        <td>0.19</td>\n",
    "        <td>0.89</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>600</td>\n",
    "        <td>300</td>\n",
    "        <td>0.85</td>\n",
    "        <td>0.24</td>\n",
    "        <td>1.09</td>\n",
    "    </tr>\n",
    "    <tr><td>....</td></tr>\n",
    "</table>\n",
    "Create line plots indicating O(m*n) time complexity, where m is max iter and n is local search iteration. You can compute \"growth rate\" of time between each i-th and i-1-th iteration and prove they are increased by m*n\n"
   ],
   "metadata": {
    "id": "B154_AMTVQrP"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "UV_MnwFXbIgI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Task 3. Implement Simulated Annealing </h2> with following options for \"cooling\" the temperature:\n",
    "\n",
    "*   Linear Cooling Schedule: Tk = T0 − α⋅k, where T0 is initial temperature, α is a constant and k is iteration number.\n",
    "*   Logarithmic Cooling Schedule: Tk = (T0)/(log(k+1)), where T0 is initial temperature and k is iteration number\n",
    "*   Exponential Cooling Schedule: Tk = T0 ⋅ B^k, where T0 is initial temperature, k is iteration number and 0 < β < 1 is cooling rate\n",
    "*   Adaptive Cooling Schedule: An adaptive temperature schedule adjusts the cooling rate based on the algorithm's performance, such as the acceptance rate of new solutions. The idea is to slow down the cooling process if the algorithm is still finding better solutions and to speed it up if the algorithm is stagnating\n",
    "*   Custom cooling schedule: A custom temperature schedule can be designed to fit specific problem characteristics or based on empirical observations. Get creative in this one. It does not have to work better, but have an explanation of your idea.\n"
   ],
   "metadata": {
    "id": "2W3pfeXEbI4u"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "23MRTt55fALl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Task 4. Evaluate implemented temperature schedulers </h2>  in terms of:\n",
    "\n",
    "*   Exploration vs. Exploitation: if the cooling schedule is too aggressive, the algorithm may converge prematurely, settling in local minima instead of finding the global minimum\n",
    "*   Convergence Speed: well-tuned cooling schedule can significantly reduce the number of iterations required to converge to a good solution.\n",
    "*   Quality of Solutions: A gradual cooling schedule tends to yield better quality solutions since it allows the algorithm to explore the solution space longer before committing to a particular region.\n",
    "\n",
    "Define Metrics for Evaluation:\n",
    "*   Exploration vs. Exploitation: Measure the acceptance rate of worse solutions over iterations\n",
    "*   Convergence Speed: Track the number of iterations taken to reach a solution within a predefined tolerance\n",
    "*   Quality of Solutions: Compare the final solution obtained by different temperature schedulers to the known optimal or global minimum value\n",
    "*   Report hyperparameters which will make SA never converge. Why?\n",
    "\n",
    "<p> Use Rastrigin function  as objective function for evaluation. Google how it looks, it is a function with a lot of local minima and only one global minima. You will have to run each setup multiple times. Create a table with results, visualize it using boxplots (for example). Compare mean values of metrics and based on that draw conclusions. </p>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/8/8b/Rastrigin_function.png\" alt=\"Example Image\" width=\"300\" height=\"200\">\n"
   ],
   "metadata": {
    "id": "SSk34lDIfAnc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def rastrigin(x):\n",
    "    A = 10\n",
    "    n = len(x) # determine the dimensions\n",
    "    return A * n + sum(x_i**2 - A * np.cos(2 * np.pi * x_i) for x_i in x)\n",
    "\n",
    "# Example usage\n",
    "x = np.array([1.2, 2.3]) # you can work 2 dimensions so it is easier to visualize later\n",
    "value = rastrigin(x)\n",
    "print(f'Rastrigin function value at {x}: {value}')"
   ],
   "metadata": {
    "id": "7s5mwdyvg0Fa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Task 5. Implement Particle Swarm Optimization algorithm </h2>\n",
    "Select a multidimensional function to optimize (e.g., Rosenbrock function, Rastrigin function, or Griewank function).\n",
    "\n",
    "\n",
    "1.  Define a class for the particle that includes properties such as position, velocity, personal best position, and personal best value.\n",
    "2.  Initialize a swarm of particles with random positions and velocities within defined boundaries.\n",
    "3.  Implement PSO formula for position update\n",
    "4.  Create a running loop, which perform the optimization\n"
   ],
   "metadata": {
    "id": "LXD0P4iuisrc"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "PhdTYcS3juvB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Task 6. Experiment with C1 and C2 hyperparameters </h2>\n",
    "The goal of this project is to investigate the effects of the cognitive coefficient (c1) social coefficient (c2) and inertia weight (w) on the convergence behavior of the Particle Swarm Optimization algorithm.\n",
    "\n",
    "\n",
    "1.   Ensure that you have a working implementation of PSO (Task 5)\n",
    "2.   Conduct Experiments:\n",
    "\n",
    "* For each combination of c1,c2 and w, run the PSO algorithm multiple times (e.g., 30 runs) to account for randomness and obtain average results\n",
    "* Vary the hyperparameters c1, c2, w: Track and record the following metrics for each configuration (Best solution found, Number of iterations to convergence, Average time taken per run)\n",
    "* Create plots to visualize convergence speeds and best solutions over iterations for different parameter settings\n",
    "\n",
    "<p> 3.) Report hyperparameters which will make PSO never converge. Why?</p>"
   ],
   "metadata": {
    "id": "tZ3FZrcejvGg"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "bEa3C9Collhu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Task 7. Experiment with C1=0 and C2=1 </h2>\n",
    "<p> Fix other hyperparemeters to meaningful values and use c1=0 and c2=1 </p>\n",
    "<p> How does PSO behave? Is this reminding you of other algorithm? Why? </p>\n"
   ],
   "metadata": {
    "id": "TutYp0R0llrV"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "T23aPSkynH1S"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Explain your results:"
   ],
   "metadata": {
    "id": "wEyE3e6YnIWY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Task 8. Implement Ant Colony Optimization </h2>\n",
    "Use the Traveling Salesman Problem (TSP) as the objective function for this task. The TSP is a classic optimization problem where the goal is to find the shortest possible route that visits each city exactly once and returns to the origin city.\n",
    "<p>Objective Function: For a given set of cities and their pairwise distances, the objective function can be defined as sum of all distances or f(x)=Total Distance of the Route</p>\n",
    "\n",
    "1.   Define the number of ants, the pheromone matrix, and the heuristic information (usually the inverse of the distance)\n",
    "2.   Implement a pheromone update rule that allows pheromones to evaporate over time and be deposited by ants based on the quality of the solution found\n",
    "3.   Define how ants choose their next city based on pheromone levels and heuristic information (using a probability-based approach)\n",
    "4.   Finish the implementation and create loop which optimizes the objective function\n"
   ],
   "metadata": {
    "id": "HRP5vOCsnLVZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "  Small example\n",
    "'''\n",
    "distance_matrix = np.array([\n",
    "    [0, 3.16, 4.00, 6.08, 3.00],  # Distances from city A\n",
    "    [3.16, 0, 3.00, 5.10, 3.16],   # Distances from city B\n",
    "    [4.00, 3.00, 0, 3.16, 1.00],    # Distances from city C\n",
    "    [6.08, 5.10, 3.16, 0, 3.16],    # Distances from city D\n",
    "    [3.00, 3.16, 1.00, 3.16, 0]     # Distances from city E\n",
    "])\n",
    "\n",
    "# List of cities\n",
    "cities = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "'''\n",
    "  Bigger example\n",
    "'''\n",
    "distance_matrix_big = np.array([\n",
    "    [0.00, 3.61, 5.00, 7.07, 4.12, 6.08, 5.66, 6.08, 8.06, 2.24],  # Distances from city A\n",
    "    [3.61, 0.00, 3.16, 5.10, 1.00, 4.12, 3.16, 3.16, 6.32, 1.00],  # Distances from city B\n",
    "    [5.00, 3.16, 0.00, 3.16, 4.12, 1.00, 3.16, 3.16, 3.16, 3.16],  # Distances from city C\n",
    "    [7.07, 5.10, 3.16, 0.00, 5.00, 2.83, 3.16, 4.12, 3.16, 5.00],  # Distances from city D\n",
    "    [4.12, 1.00, 4.12, 5.00, 0.00, 4.12, 3.16, 2.24, 6.32, 3.16],  # Distances from city E\n",
    "    [6.08, 4.12, 1.00, 2.83, 4.12, 0.00, 3.16, 3.16, 4.12, 4.12],  # Distances from city F\n",
    "    [5.66, 3.16, 3.16, 3.16, 3.16, 3.16, 0.00, 3.16, 4.12, 3.16],  # Distances from city G\n",
    "    [6.08, 3.16, 3.16, 4.12, 2.24, 3.16, 3.16, 0.00, 5.00, 2.83],  # Distances from city H\n",
    "    [8.06, 6.32, 3.16, 3.16, 6.32, 4.12, 4.12, 5.00, 0.00, 6.08],  # Distances from city I\n",
    "    [2.24, 1.00, 3.16, 5.00, 3.16, 4.12, 3.16, 2.83, 6.08, 0.00]   # Distances from city J\n",
    "])\n",
    "\n",
    "# List of cities\n",
    "cities_big = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "\n",
    "\n",
    "# You will probably need this:\n",
    "def euclidean_distance(point1, point2):\n",
    "    return np.sqrt(np.sum((point1 - point2) ** 2))"
   ],
   "metadata": {
    "id": "cEQWb2tuoQ93"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "-Ae7_ro6okpc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Task 9. Experiment with Ant Colony Optimization </h2>\n",
    "Experiment with:\n",
    "\n",
    "\n",
    "*   Pheromone Importance (α): Controls the influence of pheromone on the decision-making process.\n",
    "*   Heuristic Importance (β): Controls the influence of the heuristic information (e.g., distance).\n",
    "*   Pheromone Evaporation Rate (𝜌): Determines how quickly pheromone evaporates over time.\n",
    "*   Number of Ants: The size of the ant population.\n",
    "\n",
    "<p> 1.)Run the ACO algorithm with different combinations of α,β, 𝜌, and the number of ants. For each combination, record the best tour found and the total distance. Conduct multiple trials (e.g., 30 runs) for each parameter combination to obtain reliable average results. </p>\n",
    "<p> 2.) Create plots to illustrate how changing the hyperparameters affects performance. Write a report summarizing the findings in you see in plots. </p>\n",
    "<p> 3.) What is the time complexity of Ant colony Optimization? Why? You do not have to create plots (but if you want, use previously defined approach) </p>\n",
    "<p> 4.) Report hyperparameters which will make Ant colony never converge. Why?</p>"
   ],
   "metadata": {
    "id": "rxcricaCo4l-"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "CTBXQOPRp_Ja"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Your Answer"
   ],
   "metadata": {
    "id": "NNoQcM2GqByJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Task 10. Implement Genetic Algorithm (GA) Optimization </h2>\n",
    "The goal of this task is to implement a Genetic Algorithm to solve an optimization problem. GA can optimize continuous (numeric) and discrete (categorical) problems. For example\n",
    "\n",
    "*   Rastrigin, an example of continous objective function you have implemented above. But use at least 10 dimnesions. Check code bellow.\n",
    "*   Knapsack Problem, the Knapsack Problem is a classic optimization problem where the goal is to maximize the total value of items that can be placed into a knapsack without exceeding its weight capacity\n",
    "\n",
    "<p>Let's start with implementation</p>\n",
    "\n",
    "1.   Implement a selection mechanisms: tournament selection, roulette wheel selection. Their purpose is to choose individuals based on their fitness values\n",
    "2.   Implement crossover techniques to combine the genetic information of two parent individuals to create offspring. Implement, single-point crossover, 2-point crossover and uniform crossover.\n",
    "3.   Implement mutation: Introduce random mutations in offspring to maintain genetic diversity. Implement gaussian mutation for numeric problems and implement Flip-bit mutation for discrete problems.\n",
    "4.   Create a main loop which performs the optimization\n",
    "5.   Create an inner loop which creates new population based on current population\n",
    "6.   Create encoding for Knapsack problem. For example, knapsack containing only first item (out of 4) will be encoded as [1,0,0,0]. Knapsack containing second and fourth item will be encoded as [0,1,0,1], etc...\n",
    "7. Finish the fitness function for Knapsack problem\n",
    "8. Run on both problems and get results\n"
   ],
   "metadata": {
    "id": "8TUb7eQ7q3xq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Use at least 10 dimnesions in rastrigin function\n",
    "def rastrigin_high_dimen(x):\n",
    "    A = 10\n",
    "    n = len(x) # determine the dimensions\n",
    "    if n < 10:\n",
    "      print(\"Use at least 10 dimnesions in rastrigin function\")\n",
    "      return -1\n",
    "    else:\n",
    "      return A * n + sum(x_i**2 - A * np.cos(2 * np.pi * x_i) for x_i in x)\n",
    "\n",
    "# For example\n",
    "x = np.array([1.2, 2.3, 20, 3,3.2, 5.4, 42.1, 2, 1, 2, 4,5])\n",
    "value = rastrigin_high_dimen(x)\n",
    "print(f'Rastrigin function value at {x}: {value}')"
   ],
   "metadata": {
    "id": "F_V28R_GtFlS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# If you want you can add more items\n",
    "knapsack_items = {\n",
    "    'item1': {'value': 60, 'weight': 10},\n",
    "    'item2': {'value': 100, 'weight': 20},\n",
    "    'item3': {'value': 120, 'weight': 30},\n",
    "    'item4': {'value': 80, 'weight': 15},\n",
    "    'item5': {'value': 40, 'weight': 5},\n",
    "    'item6': {'value': 70, 'weight': 25},\n",
    "    'item7': {'value': 90, 'weight': 35},\n",
    "    'item8': {'value': 150, 'weight': 40},\n",
    "    'item9': {'value': 200, 'weight': 50},\n",
    "    'item10': {'value': 30, 'weight': 10}\n",
    "}\n",
    "\n",
    "# Maximum weight capacity of the knapsack\n",
    "capacity = 100\n",
    "\n",
    "def fitness(individual):\n",
    "    \"\"\"Calculate the fitness of an individual.\"\"\"\n",
    "    total_value = # Sum of all values contained in the knapsack (individual)\n",
    "    total_weight = # Sum of all weights contained in the knapsack (individual)\n",
    "\n",
    "    if total_weight > capacity:\n",
    "        return 0  # Penalize individuals that exceed the capacity\n",
    "    return total_value"
   ],
   "metadata": {
    "id": "gtX9pXxPv2ki"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Task 11. Experiment with Genetic Algorithm (GA) Optimization Hyperparameters </h2>\n",
    "Identify key hyperparameters to experiment with, such as:\n",
    "\n",
    "*   Population Size: The number of individuals in the population\n",
    "*   Crossover type: Single point vs 2-point vs uniform\n",
    "*   Mutation Rate: The probability of mutating a chromosome.\n",
    "*   Selection Method: The method used for selecting parents from the populatio\n",
    "<p> 1.) Run the Genetic Algorithm with different combinations of population size, crossover type, mutation rate, and selection methods.\n",
    "For each combination, record metrics such as the best fitness value found and the number of generations required to converge to a solution.\n",
    "</p>\n",
    "<p> 2.) Report hyperparameters which will make GA never converge. Why?</p>"
   ],
   "metadata": {
    "id": "nQKVvw7ftF1Z"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "jaR9fmOFvEsS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Task 12. Use pyGAD library </h2>\n",
    "The pyGAD library is a powerful tool for implementing Genetic Algorithms in Python. Check their documentation: https://pygad.readthedocs.io/en/latest/\n",
    "\n",
    "1.   pip install pygad\n",
    "2.   Solve Knapsack problem defined above\n",
    "3.   Solve rastrigin_high_dimen problem defined above\n",
    "4.   Explore pyGAD hyperparameters\n"
   ],
   "metadata": {
    "id": "DWs5dObhwriw"
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install pygad"
   ],
   "metadata": {
    "id": "KJrOOGmdxuTd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pygad"
   ],
   "metadata": {
    "id": "q-kClVlZxnFu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Task 13. The Needleman-Wunch Algorithm </h2>\n",
    "The goal of this task is to implement basic Needleman-Wunsch algorithm for sequence alignment and to experiment with various scoring parameters to understand their impact on alignment quality.\n",
    "\n",
    "1.   Initialization: Create a scoring matrix initialized with zeros. The dimensions of the matrix should be based on the lengths of the two sequences being aligned.\n",
    "2.   Scoring System: Define a scoring system that includes: Match Score: The score for matching characters, Mismatch Penalty: The penalty for aligning different characters, Gap Penalty: The penalty for introducing gaps in the alignment.\n",
    "3.   Implement filling the Matrix: Fill in the scoring matrix according to the Needleman-Wunsch algorithm rules.\n",
    "4.   Implement Traceback: After filling the matrix, perform a traceback to construct the aligned sequences.\n",
    "<p>\n",
    "Here are two sequences which you can use for example run:\n",
    "*   S1 = \"ACTGACTGAACCCAA\"\n",
    "*   S2 = \"ACTGATCAA\"\n",
    "</p>\n",
    "In order to check your implementation correctness use the following page: https://bioboot.github.io/bimm143_W20/class-material/nw/\n"
   ],
   "metadata": {
    "id": "E4wKgWqDxxX_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Feel free to organize the code however you want...\n",
    "def fill_in_the_matrix():\n",
    "  pass\n",
    "\n",
    "\n",
    "def traceback():\n",
    "  pass"
   ],
   "metadata": {
    "id": "e4lTFdeBysji"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Task 14. Time complexity of The Needleman-Wunch Algorithm </h2>\n",
    "\n",
    "\n",
    "1.   What is the time complexity of The Needleman-Wunch Algorith? Both filling in and traceback\n",
    "2.   Why?\n",
    "3.   When we say time complexity, we mean O() annotation. This means worst possible case. Using the implementation from Task 12. demonstrate the worst time complexity or worst possible case."
   ],
   "metadata": {
    "id": "MeSGu-zHzHX8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Your answer here...."
   ],
   "metadata": {
    "id": "csWYPcpiz8lZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Demonstration of worst time complexity"
   ],
   "metadata": {
    "id": "yxXOXrOfz7uJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Task 15. Implement basic Gradient Descent </h2>\n",
    "The goal of this task is to implement the Basic Gradient Descent algorithm to optimize a given objective function.\n",
    "\n",
    "\n",
    "\n",
    "1.   Select an Objective Function, I would recommend quadratic because this is often used in examples. f(x)=ax^2 + bx + c. Feel free to try complex ones used in tasks above\n",
    "\n",
    "2.   Define a function to compute the gradient of the objective function. We will assume we do not know how to compute the gradient, therefore we have to estimate it. Implement numerical gradient estimation\n",
    "3.   Update Rule: Implement the update rule for the gradient descent based on learning rate\n"
   ],
   "metadata": {
    "id": "9EDL6YpU0AyY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the objective function\n",
    "def quadratic_objective_function(x):\n",
    "    return (x - 3)**2 + 1\n",
    "\n",
    "# Define the numerical gradient estimation\n",
    "def numerical_gradient(f, x, h=1e-5):\n",
    "    '''\n",
    "      Implement numerical gradient estimation\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "def gradient_descent(starting_point, learning_rate, num_iterations):\n",
    "    x = starting_point\n",
    "    x_history = []  # To store the history of x values, for visuzalizaton\n",
    "    f_history = []  # To store the history of function values, for visuzalizaton\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "    '''\n",
    "      Implement basic gradient descent\n",
    "    '''\n",
    "\n",
    "    return x, f_history, x_history"
   ],
   "metadata": {
    "id": "Vg-_2PD50n91"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Task 16. Experiment basic Gradient Descent </h2>\n",
    "To compare the effect of varying the step size h used in the numerical gradient estimation and the learning rate in the Gradient Descent algorithm, we will set up an experiment using both the exact gradient of a quadratic function and the numerically estimated gradient. We will analyze how changes in ℎ and the learning rate (lr) affect convergence.\n",
    "\n",
    "\n",
    "\n",
    "1.   Experiment with lr,h and exact derivative vs numerical estimate\n",
    "2.   Record and visualize results\n",
    "3.   Use f_history and x_history to visualize path during the optimization\n",
    "4.   Draw conclusions and support them with figures from (3.). How is h and lr affecting convergance? Exact derivative vs numerical estimate?\n"
   ],
   "metadata": {
    "id": "QRCwij8T2Q7K"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# What is the exact derivative of quadratic_objective_function\n",
    "def the_exact_derivative(x):\n",
    "  pass\n",
    "\n",
    "# Change those accordingly\n",
    "starting_point = 5  # Starting point for the gradient descent\n",
    "h_values = [0.1, 1e-5, 1e-10, ...]  # Different step sizes for numerical gradient. Evaluate more than 3 values\n",
    "learning_rates = [0.1, 0.01, 0.5, ...]  # Different learning rates. Evaluate more than 3 values\n",
    "num_iterations = 20  # Number of iterations\n",
    "\n",
    "results = {} # Store results\n",
    "for h in h_values:\n",
    "    for lr in learning_rates:\n",
    "      '''\n",
    "        Run gradient descent with exact derivative\n",
    "        Run gradient descent with numerical estimate\n",
    "        Record h,lr, convergance time (did it converge), other important metrics you want to compare, path (history)\n",
    "      '''"
   ],
   "metadata": {
    "id": "weGpeDuZ2fkv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Your answer here"
   ],
   "metadata": {
    "id": "YLZycaCW4YaU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Task 17. The end game - part 1</h2>\n",
    "The goal of this task is to tackle a challenging optimization problem using different optimization algorithms. The problem is defined bellow, select appropriate algorithms, compare their performances, and utilize a simpler algorithm (Hill Climber) to fine-tune hyperparameters for more complex algorithms.\n",
    "\n",
    "\n",
    "1.   Understand the Problem: Clearly define the optimization problem, including the objective function, constraints, and any relevant parameters.\n",
    "\n",
    "2.   Select Algorithms: Choose at least two algorithms for the problem optimization. Justify the choice of algorithms based on their suitability for the selected problem.\n",
    "3. Implement the Algorithms\n",
    "4. Hyperparameter Optimization with a Simple Algorithm (Hill Climber)\n",
    "5. Experimentation and Comparison: Run experiments using the implemented algorithms with the chosen hyperparameters.\n",
    "Record metrics such as: Best solution found, Execution time, Number of iterations/generations. Analyze and compare the performance of the algorithms based on these metrics.\n",
    "6. Analyze Results: Create plots to visualize the performance of the algorithms\n",
    "\n",
    "Problem Definition\n",
    "In the Vehicle Routing Problem VRP, the goal is to determine the optimal routes for a fleet of vehicles to service a set of customers while minimizing the total distance traveled, respecting vehicle capacities and customer demands.\n",
    "\n",
    "*  Multiple Vehicles with Different Capacities: Instead of having vehicles with the same capacity, introduce vehicles that have different maximum capacities.\n",
    "\n",
    "*  Time Windows: Each customer can have specific time windows during which they must be serviced. If a vehicle arrives outside of this window, it may incur a penalty or be unable to service that customer.\n",
    "\n",
    "*  Service Times: Include service times at each customer location. This means that the total route time will be affected not only by travel distance but also by the time spent servicing each customer.\n",
    "\n",
    "*  Limited Number of Routes: Set a limit on the number of routes that can be used, forcing optimization under tighter constraints.\n",
    "\n",
    "*  Penalty for Late Deliveries: Introduce a penalty for delivering goods late, based on how late the vehicle arrives at a customer.\n",
    "\n",
    "<h3>Params in the data </h3>\n",
    "\n",
    "<p> demand:This represents the quantity of goods or services that the customer\n",
    "requires. It is important for the vehicle routing problem as it dictates how much of the vehicle's capacity is used when serving that customer. For example, if a customer has a demand of 10, the vehicle must have at least that much capacity to service this customer. </p>\n",
    "<p> (x, y): This tuple represents the coordinates of the customer's location on a two-dimensional plane. The coordinates are used to calculate the distance between customers and the depot. For example, (3, 5) means the customer is located at 3 units on the x-axis and 5 units on the y-axis. </p>\n",
    "<p> service_time: This indicates the amount of time required to service the customer once the vehicle arrives at their location. Service time affects the overall route time, as it adds to the total time spent at each customer before moving on to the next one. </p>\n",
    "<p>  (earliest_time, latest_time): This tuple defines the time window during which the customer must be serviced.\n",
    "earliest_time: The earliest moment the vehicle can arrive at the customer's location. </p>\n",
    "<p>  latest_time: The latest moment the vehicle can arrive without incurring a penalty or missing the service. This aspect is crucial for routing decisions, as it adds constraints to the schedule that must be respected. </p>"
   ],
   "metadata": {
    "id": "Oq8tdTvx4aKv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the customers with (customer_id, demand, (x, y), service_time, (earliest_time, latest_time))\n",
    "\n",
    "customers = [\n",
    "    ('Customer1', 5, (1, 2), 2, (0, 10)),\n",
    "    ('Customer2', 10, (2, 3), 3, (2, 12)),\n",
    "    ('Customer3', 8, (3, 1), 1, (1, 8)),\n",
    "    ('Customer4', 6, (4, 4), 2, (3, 15)),\n",
    "    ('Customer5', 12, (5, 5), 4, (5, 15)),\n",
    "    ('Customer6', 7, (6, 2), 1, (0, 5)),\n",
    "    ('Customer7', 15, (7, 8), 3, (5, 20)),\n",
    "    ('Customer8', 4, (8, 3), 2, (3, 9)),\n",
    "    ('Customer9', 9, (1, 7), 1, (2, 10)),\n",
    "    ('Customer10', 11, (4, 6), 2, (4, 14)),\n",
    "    ('Customer11', 14, (2, 5), 3, (1, 9)),\n",
    "    ('Customer12', 6, (5, 7), 2, (3, 12)),\n",
    "    ('Customer13', 10, (3, 3), 4, (2, 10)),\n",
    "    ('Customer14', 8, (6, 5), 1, (0, 4)),\n",
    "    ('Customer15', 12, (1, 4), 2, (1, 7)),\n",
    "    ('Customer16', 5, (4, 2), 3, (3, 8)),\n",
    "    ('Customer17', 7, (8, 6), 1, (4, 10)),\n",
    "    ('Customer18', 9, (5, 3), 2, (2, 9)),\n",
    "    ('Customer19', 11, (3, 6), 2, (4, 11)),\n",
    "    ('Customer20', 13, (2, 8), 4, (3, 15)),\n",
    "]\n",
    "# Define the depot location\n",
    "depot = (0, 0)\n",
    "\n",
    "# Define the vehicles with different capacities\n",
    "vehicles = [\n",
    "    {'vehicle_id': 'Vehicle1', 'capacity': 20},\n",
    "    {'vehicle_id': 'Vehicle2', 'capacity': 15},\n",
    "    {'vehicle_id': 'Vehicle3', 'capacity': 25},\n",
    "]\n",
    "\n",
    "# Routing rules\n",
    "routing_rules = {\n",
    "    'max_distance_per_route': 30,  # Maximum distance a vehicle can travel in one route\n",
    "    'max_customers_per_route': 5,   # Maximum number of customers a vehicle can serve in one route\n",
    "}"
   ],
   "metadata": {
    "id": "118tXJli6rrf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Task 18. The end game - part 2 </h2>\n",
    "The goal of this task is for you to research, implement, and analyze a <b> at least two </b> metaheuristic optimization algorithm that was not covered in class. You will apply the algorithm to a chosen optimization problem, demonstrating its effectiveness and comparing it to other methods.\n",
    "<p> Some ideas: </p>\n",
    "Gravitational Search Algorithm, Bat Algorithm, Differential Evolution (DE), Cuckoo Search (CS), Firefly Algorithm, Harmony Search (HS), Tabu Search, Affine GAP Cost Needleman-Wunch etc....\n",
    "<h3> There are many algorithms to consider...</h3>\n",
    "You have to:\n",
    "\n",
    "\n",
    "*   Implement the algorithm\n",
    "*   What is the time complexity?\n",
    "*   Analyze hyperparams\n",
    "*   Visualize the performance\n",
    "*   Pick objective function of your choice\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "k7R98Bqv9HwI"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "AxHGzql99n2F"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
